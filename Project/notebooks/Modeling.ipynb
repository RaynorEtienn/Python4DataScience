{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c97a482c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662a082c",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89299dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (19140, 47)\n",
      "Churn Rate: 22.31%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>level</th>\n",
       "      <th>platform</th>\n",
       "      <th>is_thumbs_up</th>\n",
       "      <th>is_thumbs_down</th>\n",
       "      <th>is_ad</th>\n",
       "      <th>is_error</th>\n",
       "      <th>is_song</th>\n",
       "      <th>length</th>\n",
       "      <th>downgrade</th>\n",
       "      <th>songs_last_1d</th>\n",
       "      <th>errors_last_1d</th>\n",
       "      <th>listen_time_last_1d</th>\n",
       "      <th>unique_artists_last_1d</th>\n",
       "      <th>unique_songs_last_1d</th>\n",
       "      <th>songs_last_3d</th>\n",
       "      <th>errors_last_3d</th>\n",
       "      <th>listen_time_last_3d</th>\n",
       "      <th>unique_artists_last_3d</th>\n",
       "      <th>unique_songs_last_3d</th>\n",
       "      <th>songs_last_7d</th>\n",
       "      <th>errors_last_7d</th>\n",
       "      <th>listen_time_last_7d</th>\n",
       "      <th>unique_artists_last_7d</th>\n",
       "      <th>unique_songs_last_7d</th>\n",
       "      <th>songs_last_14d</th>\n",
       "      <th>errors_last_14d</th>\n",
       "      <th>listen_time_last_14d</th>\n",
       "      <th>unique_artists_last_14d</th>\n",
       "      <th>unique_songs_last_14d</th>\n",
       "      <th>songs_last_30d</th>\n",
       "      <th>errors_last_30d</th>\n",
       "      <th>listen_time_last_30d</th>\n",
       "      <th>unique_artists_last_30d</th>\n",
       "      <th>unique_songs_last_30d</th>\n",
       "      <th>account_lifetime</th>\n",
       "      <th>avg_songs_per_day</th>\n",
       "      <th>thumbs_ratio</th>\n",
       "      <th>errors_per_song</th>\n",
       "      <th>trend_songs_7d_vs_30d</th>\n",
       "      <th>trend_listen_time_7d_vs_30d</th>\n",
       "      <th>total_sessions</th>\n",
       "      <th>avg_days_between_sessions</th>\n",
       "      <th>avg_songs_per_session</th>\n",
       "      <th>avg_session_duration</th>\n",
       "      <th>target</th>\n",
       "      <th>state_freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000025</th>\n",
       "      <td>M</td>\n",
       "      <td>paid</td>\n",
       "      <td>Windows</td>\n",
       "      <td>94</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1662</td>\n",
       "      <td>417296.59169</td>\n",
       "      <td>0</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>52648.44590</td>\n",
       "      <td>197</td>\n",
       "      <td>208</td>\n",
       "      <td>535</td>\n",
       "      <td>1</td>\n",
       "      <td>132961.53374</td>\n",
       "      <td>440</td>\n",
       "      <td>502</td>\n",
       "      <td>687</td>\n",
       "      <td>1</td>\n",
       "      <td>173744.74643</td>\n",
       "      <td>552</td>\n",
       "      <td>645</td>\n",
       "      <td>1049</td>\n",
       "      <td>1</td>\n",
       "      <td>265573.95039</td>\n",
       "      <td>803</td>\n",
       "      <td>965</td>\n",
       "      <td>1662</td>\n",
       "      <td>1</td>\n",
       "      <td>417296.59169</td>\n",
       "      <td>1162</td>\n",
       "      <td>1468</td>\n",
       "      <td>100.460382</td>\n",
       "      <td>16.380778</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>1.653032</td>\n",
       "      <td>1.665430</td>\n",
       "      <td>17</td>\n",
       "      <td>5.909434</td>\n",
       "      <td>97.764706</td>\n",
       "      <td>24546.858335</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000035</th>\n",
       "      <td>F</td>\n",
       "      <td>paid</td>\n",
       "      <td>Linux</td>\n",
       "      <td>117</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1266</td>\n",
       "      <td>310364.86590</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>41213.98983</td>\n",
       "      <td>160</td>\n",
       "      <td>168</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>41213.98983</td>\n",
       "      <td>160</td>\n",
       "      <td>168</td>\n",
       "      <td>405</td>\n",
       "      <td>1</td>\n",
       "      <td>99705.54700</td>\n",
       "      <td>347</td>\n",
       "      <td>388</td>\n",
       "      <td>574</td>\n",
       "      <td>1</td>\n",
       "      <td>140551.62871</td>\n",
       "      <td>472</td>\n",
       "      <td>544</td>\n",
       "      <td>1133</td>\n",
       "      <td>1</td>\n",
       "      <td>278412.10335</td>\n",
       "      <td>835</td>\n",
       "      <td>1042</td>\n",
       "      <td>63.350567</td>\n",
       "      <td>19.673486</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>1.429328</td>\n",
       "      <td>1.432487</td>\n",
       "      <td>21</td>\n",
       "      <td>3.016694</td>\n",
       "      <td>60.285714</td>\n",
       "      <td>14779.279329</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000083</th>\n",
       "      <td>M</td>\n",
       "      <td>paid</td>\n",
       "      <td>Windows</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>501</td>\n",
       "      <td>122606.27093</td>\n",
       "      <td>0</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>52170.90103</td>\n",
       "      <td>203</td>\n",
       "      <td>211</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>61312.53977</td>\n",
       "      <td>236</td>\n",
       "      <td>247</td>\n",
       "      <td>406</td>\n",
       "      <td>0</td>\n",
       "      <td>100331.33604</td>\n",
       "      <td>358</td>\n",
       "      <td>391</td>\n",
       "      <td>501</td>\n",
       "      <td>0</td>\n",
       "      <td>122606.27093</td>\n",
       "      <td>427</td>\n",
       "      <td>478</td>\n",
       "      <td>501</td>\n",
       "      <td>0</td>\n",
       "      <td>122606.27093</td>\n",
       "      <td>427</td>\n",
       "      <td>478</td>\n",
       "      <td>34.668854</td>\n",
       "      <td>14.045868</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.238931</td>\n",
       "      <td>3.273275</td>\n",
       "      <td>11</td>\n",
       "      <td>3.151714</td>\n",
       "      <td>45.545455</td>\n",
       "      <td>11146.024630</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000103</th>\n",
       "      <td>F</td>\n",
       "      <td>paid</td>\n",
       "      <td>Linux</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>13554.73009</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>984.08263</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>984.08263</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>984.08263</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>3785.68327</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>3785.68327</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>47.459201</td>\n",
       "      <td>1.176247</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.086957</td>\n",
       "      <td>1.039684</td>\n",
       "      <td>3</td>\n",
       "      <td>15.819734</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>4518.243363</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000164</th>\n",
       "      <td>F</td>\n",
       "      <td>paid</td>\n",
       "      <td>Windows</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>847</td>\n",
       "      <td>209060.65753</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>42443.54099</td>\n",
       "      <td>173</td>\n",
       "      <td>183</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>50847.03993</td>\n",
       "      <td>202</td>\n",
       "      <td>215</td>\n",
       "      <td>313</td>\n",
       "      <td>0</td>\n",
       "      <td>75785.07918</td>\n",
       "      <td>286</td>\n",
       "      <td>306</td>\n",
       "      <td>479</td>\n",
       "      <td>1</td>\n",
       "      <td>117207.44962</td>\n",
       "      <td>400</td>\n",
       "      <td>450</td>\n",
       "      <td>513</td>\n",
       "      <td>1</td>\n",
       "      <td>126008.87092</td>\n",
       "      <td>426</td>\n",
       "      <td>480</td>\n",
       "      <td>99.147500</td>\n",
       "      <td>8.457525</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>2.438644</td>\n",
       "      <td>2.405699</td>\n",
       "      <td>15</td>\n",
       "      <td>6.609833</td>\n",
       "      <td>56.466667</td>\n",
       "      <td>13937.377169</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gender level platform  is_thumbs_up  is_thumbs_down  is_ad  is_error  \\\n",
       "userId                                                                         \n",
       "1000025      M  paid  Windows            94              13      7         1   \n",
       "1000035      F  paid    Linux           117              15      6         1   \n",
       "1000083      M  paid  Windows            21               2      8         0   \n",
       "1000103      F  paid    Linux             2               1      3         0   \n",
       "1000164      F  paid  Windows            38               6     20         1   \n",
       "\n",
       "         is_song        length  downgrade  songs_last_1d  errors_last_1d  \\\n",
       "userId                                                                     \n",
       "1000025     1662  417296.59169          0            212               0   \n",
       "1000035     1266  310364.86590          0            170               0   \n",
       "1000083      501  122606.27093          0            213               0   \n",
       "1000103       57   13554.73009          0              5               0   \n",
       "1000164      847  209060.65753          0            184               0   \n",
       "\n",
       "         listen_time_last_1d  unique_artists_last_1d  unique_songs_last_1d  \\\n",
       "userId                                                                       \n",
       "1000025          52648.44590                     197                   208   \n",
       "1000035          41213.98983                     160                   168   \n",
       "1000083          52170.90103                     203                   211   \n",
       "1000103            984.08263                       5                     5   \n",
       "1000164          42443.54099                     173                   183   \n",
       "\n",
       "         songs_last_3d  errors_last_3d  listen_time_last_3d  \\\n",
       "userId                                                        \n",
       "1000025            535               1         132961.53374   \n",
       "1000035            170               0          41213.98983   \n",
       "1000083            250               0          61312.53977   \n",
       "1000103              5               0            984.08263   \n",
       "1000164            216               0          50847.03993   \n",
       "\n",
       "         unique_artists_last_3d  unique_songs_last_3d  songs_last_7d  \\\n",
       "userId                                                                 \n",
       "1000025                     440                   502            687   \n",
       "1000035                     160                   168            405   \n",
       "1000083                     236                   247            406   \n",
       "1000103                       5                     5              5   \n",
       "1000164                     202                   215            313   \n",
       "\n",
       "         errors_last_7d  listen_time_last_7d  unique_artists_last_7d  \\\n",
       "userId                                                                 \n",
       "1000025               1         173744.74643                     552   \n",
       "1000035               1          99705.54700                     347   \n",
       "1000083               0         100331.33604                     358   \n",
       "1000103               0            984.08263                       5   \n",
       "1000164               0          75785.07918                     286   \n",
       "\n",
       "         unique_songs_last_7d  songs_last_14d  errors_last_14d  \\\n",
       "userId                                                           \n",
       "1000025                   645            1049                1   \n",
       "1000035                   388             574                1   \n",
       "1000083                   391             501                0   \n",
       "1000103                     5              18                0   \n",
       "1000164                   306             479                1   \n",
       "\n",
       "         listen_time_last_14d  unique_artists_last_14d  unique_songs_last_14d  \\\n",
       "userId                                                                          \n",
       "1000025          265573.95039                      803                    965   \n",
       "1000035          140551.62871                      472                    544   \n",
       "1000083          122606.27093                      427                    478   \n",
       "1000103            3785.68327                       18                     18   \n",
       "1000164          117207.44962                      400                    450   \n",
       "\n",
       "         songs_last_30d  errors_last_30d  listen_time_last_30d  \\\n",
       "userId                                                           \n",
       "1000025            1662                1          417296.59169   \n",
       "1000035            1133                1          278412.10335   \n",
       "1000083             501                0          122606.27093   \n",
       "1000103              18                0            3785.68327   \n",
       "1000164             513                1          126008.87092   \n",
       "\n",
       "         unique_artists_last_30d  unique_songs_last_30d  account_lifetime  \\\n",
       "userId                                                                      \n",
       "1000025                     1162                   1468        100.460382   \n",
       "1000035                      835                   1042         63.350567   \n",
       "1000083                      427                    478         34.668854   \n",
       "1000103                       18                     18         47.459201   \n",
       "1000164                      426                    480         99.147500   \n",
       "\n",
       "         avg_songs_per_day  thumbs_ratio  errors_per_song  \\\n",
       "userId                                                      \n",
       "1000025          16.380778      0.878505         0.000602   \n",
       "1000035          19.673486      0.886364         0.000790   \n",
       "1000083          14.045868      0.913043         0.000000   \n",
       "1000103           1.176247      0.666667         0.000000   \n",
       "1000164           8.457525      0.863636         0.001181   \n",
       "\n",
       "         trend_songs_7d_vs_30d  trend_listen_time_7d_vs_30d  total_sessions  \\\n",
       "userId                                                                        \n",
       "1000025               1.653032                     1.665430              17   \n",
       "1000035               1.429328                     1.432487              21   \n",
       "1000083               3.238931                     3.273275              11   \n",
       "1000103               1.086957                     1.039684               3   \n",
       "1000164               2.438644                     2.405699              15   \n",
       "\n",
       "         avg_days_between_sessions  avg_songs_per_session  \\\n",
       "userId                                                      \n",
       "1000025                   5.909434              97.764706   \n",
       "1000035                   3.016694              60.285714   \n",
       "1000083                   3.151714              45.545455   \n",
       "1000103                  15.819734              19.000000   \n",
       "1000164                   6.609833              56.466667   \n",
       "\n",
       "         avg_session_duration  target  state_freq  \n",
       "userId                                             \n",
       "1000025          24546.858335       1    0.012487  \n",
       "1000035          14779.279329       0    0.010972  \n",
       "1000083          11146.024630       1    0.007524  \n",
       "1000103           4518.243363       0    0.031714  \n",
       "1000164          13937.377169       0    0.021003  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the processed user features\n",
    "data_path = '../data/user_features.parquet'\n",
    "df = pd.read_parquet(data_path)\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Churn Rate: {df['target'].mean():.2%}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d77bd6",
   "metadata": {},
   "source": [
    "## 2. Preprocessing & Splitting\n",
    "\n",
    "We will use a **Stratified Split** to maintain the churn ratio in both training and test sets.\n",
    "We will also define a `ColumnTransformer` to handle:\n",
    "- **Numerical Features**: Standard Scaling.\n",
    "- **Categorical Features**: One-Hot Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8600b2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Columns (3): ['gender', 'level', 'platform']\n",
      "Numerical Columns (43): ['is_thumbs_up', 'is_thumbs_down', 'is_ad', 'is_error', 'is_song'] ...\n",
      "\n",
      "Training Shape: (15312, 46)\n",
      "Test Shape: (3828, 46)\n",
      "Train Churn Rate: 22.32%\n",
      "Test Churn Rate: 22.31%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 1. Separate Features and Target\n",
    "# Check if 'userId' exists before dropping (it might be the index or already dropped)\n",
    "X = df.drop(columns=[\"target\"])\n",
    "y = df['target']\n",
    "\n",
    "# 2. Identify Column Types\n",
    "# Categorical: 'gender', 'level', 'platform' (low cardinality)\n",
    "# Note: 'state_freq' is numerical, so it goes to num_cols\n",
    "categorical_cols = ['gender', 'level', 'platform']\n",
    "numerical_cols = [c for c in X.columns if c not in categorical_cols]\n",
    "\n",
    "print(f\"Categorical Columns ({len(categorical_cols)}): {categorical_cols}\")\n",
    "print(f\"Numerical Columns ({len(numerical_cols)}): {numerical_cols[:5]} ...\")\n",
    "\n",
    "# 3. Stratified Train-Test Split\n",
    "# 20% Test, 80% Train\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining Shape: {X_train.shape}\")\n",
    "print(f\"Test Shape: {X_test.shape}\")\n",
    "print(f\"Train Churn Rate: {y_train.mean():.2%}\")\n",
    "print(f\"Test Churn Rate: {y_test.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c2f5066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Feature Matrix Shape: (15312, 50)\n"
     ]
    }
   ],
   "source": [
    "# 4. Define Preprocessing Pipeline\n",
    "# We use a Pipeline to prevent data leakage (scaling parameters learned only on train)\n",
    "\n",
    "# Numerical Transformer: Impute missing values with median, then scale\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical Transformer: Impute missing values with 'missing', then OneHotEncode\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, numerical_cols),\n",
    "        ('cat', cat_transformer, categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Verify the pipeline works on training data\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "print(f\"Processed Feature Matrix Shape: {X_train_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23277518",
   "metadata": {},
   "source": [
    "## 3. Baseline Model Evaluation\n",
    "\n",
    "We will evaluate the following industry-standard models:\n",
    "1.  **Logistic Regression**: Simple baseline for interpretability.\n",
    "2.  **Random Forest**: Robust bagging ensemble.\n",
    "3.  **XGBoost**: Gradient boosting (often SOTA for tabular data).\n",
    "4.  **LightGBM**: Faster and often more accurate gradient boosting.\n",
    "5.  **CatBoost**: Excellent for categorical features (though we OHE them here).\n",
    "\n",
    "**Metrics**:\n",
    "- **F1-Score**: Harmonic mean of precision and recall (crucial for imbalanced churn).\n",
    "- **ROC-AUC**: Ability to distinguish between classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f194f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Define Models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=RANDOM_SEED),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED),\n",
    "    # Removed use_label_encoder=False as it's deprecated and causing warnings\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss', random_state=RANDOM_SEED),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=RANDOM_SEED, verbose=-1),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0, random_state=RANDOM_SEED)\n",
    "}\n",
    "\n",
    "# Evaluation Function\n",
    "def evaluate_models(models, X, y, preprocessor):\n",
    "    results = []\n",
    "    for name, model in models.items():\n",
    "        # Create full pipeline\n",
    "        clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('classifier', model)])\n",
    "        \n",
    "        # Cross-Validation (5-fold)\n",
    "        # Added 'accuracy' to scoring\n",
    "        cv_results = cross_validate(clf, X, y, cv=5, scoring=['f1', 'roc_auc', 'accuracy'])\n",
    "        \n",
    "        results.append({\n",
    "            \"Model\": name,\n",
    "            \"F1 Score (Mean)\": cv_results['test_f1'].mean(),\n",
    "            \"F1 Score (Std)\": cv_results['test_f1'].std(),\n",
    "            \"ROC-AUC (Mean)\": cv_results['test_roc_auc'].mean(),\n",
    "            \"ROC-AUC (Std)\": cv_results['test_roc_auc'].std(),\n",
    "            \"Accuracy (Mean)\": cv_results['test_accuracy'].mean(),\n",
    "            \"Accuracy (Std)\": cv_results['test_accuracy'].std(),\n",
    "            \"CV F1 Scores\": np.round(cv_results['test_f1'], 3) # Show individual scores\n",
    "        })\n",
    "        print(f\"Evaluated {name}...\")\n",
    "        \n",
    "    return pd.DataFrame(results).sort_values(by=\"F1 Score (Mean)\", ascending=False)\n",
    "\n",
    "# Run Evaluation\n",
    "results_df = evaluate_models(models, X_train, y_train, preprocessor)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c717d0d8",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Tuning\n",
    "\n",
    "We will now optimize the hyperparameters for our top two performing models: **XGBoost** and **CatBoost**.\n",
    "We use `RandomizedSearchCV` which is more efficient than Grid Search as it samples a fixed number of parameter settings from specified distributions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce21f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define parameter grids\n",
    "xgb_params = {\n",
    "    'classifier__n_estimators': [100, 200, 300, 500],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'classifier__max_depth': [3, 4, 5, 6, 8],\n",
    "    'classifier__subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'classifier__colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'classifier__gamma': [0, 0.1, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "cat_params = {\n",
    "    'classifier__iterations': [100, 200, 300, 500],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'classifier__depth': [4, 6, 8, 10],\n",
    "    'classifier__l2_leaf_reg': [1, 3, 5, 7, 9]\n",
    "}\n",
    "\n",
    "# Helper function for tuning\n",
    "def tune_model(model, params, X, y, preprocessor, n_iter=20):\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', model)])\n",
    "    \n",
    "    search = RandomizedSearchCV(\n",
    "        pipeline, \n",
    "        param_distributions=params, \n",
    "        n_iter=n_iter, \n",
    "        scoring='f1', \n",
    "        cv=3, \n",
    "        verbose=1, \n",
    "        random_state=RANDOM_SEED, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    search.fit(X, y)\n",
    "    return search\n",
    "\n",
    "# Tune XGBoost\n",
    "print(\"--- Tuning XGBoost ---\")\n",
    "xgb_model = XGBClassifier(eval_metric='logloss', random_state=RANDOM_SEED)\n",
    "xgb_search = tune_model(xgb_model, xgb_params, X_train, y_train, preprocessor)\n",
    "\n",
    "print(f\"Best XGBoost F1: {xgb_search.best_score_:.4f}\")\n",
    "print(f\"Best XGBoost Params: {xgb_search.best_params_}\")\n",
    "\n",
    "# Tune CatBoost\n",
    "print(\"\\n--- Tuning CatBoost ---\")\n",
    "cat_model = CatBoostClassifier(verbose=0, random_state=RANDOM_SEED)\n",
    "cat_search = tune_model(cat_model, cat_params, X_train, y_train, preprocessor)\n",
    "\n",
    "print(f\"Best CatBoost F1: {cat_search.best_score_:.4f}\")\n",
    "print(f\"Best CatBoost Params: {cat_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6c3bbc",
   "metadata": {},
   "source": [
    "--- Tuning XGBoost ---\n",
    "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
    "Best XGBoost F1: 0.5699\n",
    "Best XGBoost Params: {'classifier__subsample': 0.9, 'classifier__n_estimators': 500, 'classifier__max_depth': 6, 'classifier__learning_rate': 0.2, 'classifier__gamma': 0.1, 'classifier__colsample_bytree': 0.9}\n",
    "\n",
    "\n",
    "--- Tuning CatBoost ---\n",
    "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
    "Best CatBoost F1: 0.5661\n",
    "Best CatBoost Params: {'classifier__learning_rate': 0.1, 'classifier__l2_leaf_reg': 5, 'classifier__iterations': 500, 'classifier__depth': 6}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9045ccc0",
   "metadata": {},
   "source": [
    "## 5. Ensemble Modeling (Stacking)\n",
    "\n",
    "We will now combine our tuned **XGBoost** and **CatBoost** models using a `StackingClassifier`.\n",
    "This technique uses a meta-model (Logistic Regression) to learn the best combination of the base models' predictions.\n",
    "We use the optimal hyperparameters found in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83745cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Stacking Classifier (this may take a moment)...\n",
      "Stacking F1 Score: 0.5794 (+/- 0.0204)\n",
      "Stacking ROC-AUC: 0.8507\n",
      "Stacking Accuracy: 0.8467\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "# 1. Define Tuned Models with Hardcoded Parameters\n",
    "best_xgb_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate': 0.2,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'gamma': 0.1,\n",
    "    'eval_metric': 'logloss',\n",
    "    'random_state': RANDOM_SEED\n",
    "}\n",
    "\n",
    "best_cat_params = {\n",
    "    'iterations': 500,\n",
    "    'learning_rate': 0.1,\n",
    "    'depth': 6,\n",
    "    'l2_leaf_reg': 5,\n",
    "    'verbose': 0,\n",
    "    'random_state': RANDOM_SEED\n",
    "}\n",
    "\n",
    "best_xgb = XGBClassifier(**best_xgb_params)\n",
    "best_cat = CatBoostClassifier(**best_cat_params)\n",
    "\n",
    "# 2. Create Stacking Ensemble\n",
    "# We wrap each base model in the preprocessor pipeline so they can handle the raw data\n",
    "estimators = [\n",
    "    ('xgb', Pipeline(steps=[('preprocessor', preprocessor), ('classifier', best_xgb)])),\n",
    "    ('cat', Pipeline(steps=[('preprocessor', preprocessor), ('classifier', best_cat)]))\n",
    "]\n",
    "\n",
    "# The final estimator uses the predictions of the base estimators\n",
    "# We use Logistic Regression as the meta-learner\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(random_state=RANDOM_SEED),\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 3. Evaluate Stacking Model\n",
    "print(\"Evaluating Stacking Classifier (this may take a moment)...\")\n",
    "cv_results_stack = cross_validate(stacking_clf, X_train, y_train, cv=5, scoring=['f1', 'roc_auc', 'accuracy'])\n",
    "\n",
    "print(f\"Stacking F1 Score: {cv_results_stack['test_f1'].mean():.4f} (+/- {cv_results_stack['test_f1'].std():.4f})\")\n",
    "print(f\"Stacking ROC-AUC: {cv_results_stack['test_roc_auc'].mean():.4f}\")\n",
    "print(f\"Stacking Accuracy: {cv_results_stack['test_accuracy'].mean():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
